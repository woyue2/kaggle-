{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "7995cf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "0d2c55df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dL/dY: -y*(1 + exp(-Z)) - (1 - y)/(1 - 1/(1 + exp(-Z)))\n",
      "dY/dZ: exp(-Z)/(1 + exp(-Z))**2\n",
      "dZ/dw: x\n"
     ]
    }
   ],
   "source": [
    "import sympy as sp\n",
    "from sympy.abc import y, w, x, Z, Y\n",
    "from sympy import exp, log, Derivative\n",
    "\n",
    "Y = 1/(1+exp(-Z)) \n",
    "\n",
    "f = Y\n",
    "g = 1-Y\n",
    "\n",
    "dL_df = -y/f - (1-y)/g\n",
    "df_dY = 1\n",
    "\n",
    "dL_dY = dL_df * df_dY\n",
    "\n",
    "print(\"dL/dY:\", dL_dY)\n",
    "print(\"dY/dZ:\", exp(-Z)/(1+exp(-Z))**2)  \n",
    "print(\"dZ/dw:\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "cf5e031a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle - \\frac{a}{x} + \\frac{1 - a}{1 - x}$"
      ],
      "text/plain": [
       "-a/x + (1 - a)/(1 - x)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sympy as sp\n",
    "from sympy.abc import x,f,a\n",
    "from sympy import exp, Derivative\n",
    "f = 1/(1 - exp(-x))\n",
    "Derivative(f, evaluate = True)\n",
    "f = -a * sp.log(x) - (1-a) * sp.log(1-x)\n",
    "Derivative(f, x, evaluate = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "0a498265",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readOneLine(content : str):\n",
    "    content = content[0:-1]\n",
    "    lst = content.split(',')\n",
    "    for i in range(len(lst)):\n",
    "        if lst[i] == '?':\n",
    "            return []\n",
    "        else:\n",
    "            lst[i] = int(lst[i])\n",
    "        id, f1, f2, f3, f4, f5, f6, f7, f8, f9, state = \\\n",
    "        lst[0], lst[1], lst[2], lst[3], lst[4], lst[5], lst[6], lst[7], lst[8], lst[9], lst[10]\n",
    "    return [id, f1, f2, f3, f4, f5, f6, f7, f8, f9, state]\n",
    "\n",
    "def getX(data : list):\n",
    "    x0 = 1\n",
    "    x1 = data[1]\n",
    "    x2 = data[2]\n",
    "    x3 = data[3]\n",
    "    x4 = data[4]\n",
    "    x5 = data[5]\n",
    "    x6 = data[6]\n",
    "    x7 = data[7]\n",
    "    x8 = data[8]\n",
    "    x9 = data[9]   \n",
    "    return [x0, x1, x2, x3, x4, x5, x6, x7, x8, x9]\n",
    "\n",
    "def sigmoid(z):\n",
    "    print(f'sigmoid')\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def getLoss(sig_y_pred, y):\n",
    "    res = -np.mean(y * np.log(sig_y_pred) + (1 - y) * np.log(1 - sig_y_pred))\n",
    "    print(f'getLoss {res}')\n",
    "    return res\n",
    "\n",
    "def getPartialDerivative(y_train, sig_y_pred, y_pred, X_train):\n",
    "    print('getPartialDerviative')\n",
    "    LtoY = (-1* (y_pred)) * (1/ sig_y_pred) + (1- y_pred) * (1/ (1 - sig_y_pred))  # (599,)\n",
    "    YtoZ = (-1) *np.exp(-sig_y_pred) / (1 - np.exp(-sig_y_pred))**2 # (599,)\n",
    "    ZtoW = X_train # (599,10)\n",
    "    res = (LtoY * YtoZ).T.dot(X_train)\n",
    "    assert (len(res) == 10)\n",
    "    print(f'{res}')\n",
    "    return res\n",
    "\n",
    "def updateWeight(lst_w, y_train, sig_y_pred, y_pred, X_train, learing_rate = 1e-4):\n",
    "    print(f'lr is {learning_rate}')\n",
    "    lst_w -= learning_rate * getPartialDerivative(\n",
    "        y_train, \n",
    "        sig_y_pred, \n",
    "        y_pred, \n",
    "        X_train,\n",
    "    ) # 向量 -= 梯度下降的向量    形式：矩阵\n",
    "    print(f'update w :\\n{lst_w}' )\n",
    "    return lst_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "79e40a12",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid\n",
      "getLoss 0.9376356441125466\n",
      "lr is 0.0001\n",
      "getPartialDerviative\n",
      "[1466.60594697 6730.71744279 4762.18458575 4862.56996776 4292.08718705\n",
      " 4860.12154381 5545.68025024 5215.14301679 4353.29778584 2389.66177671]\n",
      "update w :\n",
      "[ 0.85333941 -0.67307174 -0.47621846 -0.486257   -0.42920872 -0.48601215\n",
      " -0.55456803 -0.5215143  -0.43532978 -0.23896618]\n",
      "counter is 1\n",
      "\n",
      "sigmoid\n",
      "getLoss 9.668230568032639\n",
      "lr is 0.0001\n",
      "getPartialDerviative\n",
      "[-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      "update w :\n",
      "[inf inf inf inf inf inf inf inf inf inf]\n",
      "counter is 2\n",
      "\n",
      "sigmoid\n",
      "getLoss nan\n",
      "lr is 0.0001\n",
      "getPartialDerviative\n",
      "[inf inf inf inf inf inf inf inf inf inf]\n",
      "update w :\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "counter is 3\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nw/5s06sntd385dltr9fp63npnc0000gn/T/ipykernel_4937/2823264009.py:38: RuntimeWarning: divide by zero encountered in divide\n",
      "  YtoZ = (-1) *np.exp(-sig_y_pred) / (1 - np.exp(-sig_y_pred))**2 # (599,)\n",
      "/var/folders/nw/5s06sntd385dltr9fp63npnc0000gn/T/ipykernel_4937/2823264009.py:31: RuntimeWarning: divide by zero encountered in log\n",
      "  res = -np.mean(y * np.log(sig_y_pred) + (1 - y) * np.log(1 - sig_y_pred))\n",
      "/var/folders/nw/5s06sntd385dltr9fp63npnc0000gn/T/ipykernel_4937/2823264009.py:31: RuntimeWarning: invalid value encountered in multiply\n",
      "  res = -np.mean(y * np.log(sig_y_pred) + (1 - y) * np.log(1 - sig_y_pred))\n",
      "/var/folders/nw/5s06sntd385dltr9fp63npnc0000gn/T/ipykernel_4937/2823264009.py:37: RuntimeWarning: divide by zero encountered in divide\n",
      "  LtoY = (-1* (y_pred)) * (1/ sig_y_pred) + (1- y_pred) * (1/ (1 - sig_y_pred))  # (599,)\n",
      "/var/folders/nw/5s06sntd385dltr9fp63npnc0000gn/T/ipykernel_4937/2823264009.py:47: RuntimeWarning: invalid value encountered in subtract\n",
      "  lst_w -= learning_rate * getPartialDerivative(\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "file = open(\"data.csv\", \"r\")\n",
    "content = file.readlines()\n",
    "data = []\n",
    "for i in range(len(content)):\n",
    "    data.append(readOneLine(content[i]))\n",
    "data_fil = []\n",
    "for i in range(len(data)):\n",
    "    if data[i]:\n",
    "        data_fil.append(data[i])\n",
    "data = data_fil\n",
    "\n",
    "# split X_train, y_train, X_test, y_test\n",
    "X = []\n",
    "for i in range(len(data)):\n",
    "    lst = getX(data[i])\n",
    "    X.append(lst)\n",
    "Y = []\n",
    "for i in range(len(data)):\n",
    "    if (data[i][-1]) == 2: \n",
    "        Y.append(0) # 良性\n",
    "    else:\n",
    "        Y.append(1) # 阴性\n",
    "        \n",
    "X_train, X_test = np.array(X[0:599]), np.array(X[600:])\n",
    "y_train, y_test = np.array(Y[0:599]), np.array(Y[600:])\n",
    "\n",
    "# initiate w_i\n",
    "# lst_w = [w0, w1, w2, w3, w4, w5, w6, w7, w8, w9] \n",
    "lst_w = np.array([1., \n",
    "                  0., \n",
    "                  0.,\n",
    "                  0.,\n",
    "                  0.,\n",
    "                  0.,\n",
    "                  0.,\n",
    "                  0.,\n",
    "                  0.,\n",
    "                  0.])\n",
    "loss = 1\n",
    "# iterate\n",
    "counter = 0\n",
    "while (loss > 1e-11):\n",
    "    y_pred = np.dot(X_train, lst_w)\n",
    "    sig_y_pred = sigmoid(y_pred)\n",
    "    loss = getLoss(sig_y_pred, y_train)\n",
    "    lst_w = updateWeight(lst_w, y_train, sig_y_pred, y_pred, X_train)\n",
    "    counter += 1\n",
    "    print(f'counter is {counter}\\n')\n",
    "    if counter > 1000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "b4a61839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "279434f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "       inf])"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "602d8ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getLoss 0.9376356441125466\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9376356441125466"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = getLoss(sig_y_pred, y_train)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "c4a3da1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1.])"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67af011",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05617d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
